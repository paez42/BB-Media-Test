{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAGE ON DEMAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Comenzar a medir el tiempo de ejecución\n",
    "start_time_ondemand = time.time()\n",
    "\n",
    "\n",
    "# Definir un User-Agent personalizado\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "\n",
    "# Configurar las opciones de Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "options.add_argument(\"--disable-gpu\")  # Desactiva la GPU para ahorrar recursos\n",
    "options.add_argument(\"--no-sandbox\")  # Previene errores en algunos sistemas\n",
    "options.add_argument(\"--disable-extensions\")  # Desactiva las extensiones para mejorar la velocidad\n",
    "options.add_argument(\"--disable-images\")  # Desactiva las imágenes para mejorar la velocidad\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.headless = True  # Ejecuta el navegador en modo headless (sin interfaz gráfica)\n",
    "\n",
    "# Iniciar el navegador con las opciones configuradas\n",
    "driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navegar a la página de Pluto.tv\n",
    "driver.get('https://pluto.tv/latam/on-demand')\n",
    "\n",
    "# Espera que la página cargue completamente (ajusta según sea necesario)\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra y haz clic en el span \"Películas\"\n",
    "span_peliculas = WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.XPATH, \"//span[text()='Películas']\")))\n",
    "span_peliculas.click()\n",
    "\n",
    "# Espera a que se cargue la sección de películas (ajusta según sea necesario)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARGAR, RECORRER ITEMS y OBTENER LINKS\n",
    "\n",
    "def process_ul_after_peliculas():\n",
    "    hrefs = []\n",
    "    ul_counter = 0  # Contador de ul procesados\n",
    "    max_scrolls = 50  # Aumentar el límite de desplazamientos\n",
    "    scrolls_done = 0  # Contador de desplazamientos realizados\n",
    "    \n",
    "    try:\n",
    "        # Encuentra el h3 con el texto \"Películas\"\n",
    "        start_h3 = driver.find_element(By.XPATH, \"//h3[text()='Películas']\")\n",
    "        print(f\"Encontrado h3: Películas\")\n",
    "        \n",
    "        # Inicia la búsqueda después del h3 \"Películas\"\n",
    "        current_element = start_h3\n",
    "        found_retro = False\n",
    "        \n",
    "        while scrolls_done < max_scrolls:\n",
    "            try:\n",
    "                ul_element = current_element.find_element(By.XPATH, \"./following::ul[1]\")  # Encuentra el primer ul después del h3\n",
    "                \n",
    "                # Procesa el ul actual\n",
    "                hrefs.extend(extract_hrefs_from_ul(ul_element))\n",
    "                ul_counter += 1\n",
    "                \n",
    "                print(f\"Procesado ul {ul_counter}\")\n",
    "                \n",
    "                # Actualiza current_element para continuar después del ul procesado\n",
    "                current_element = ul_element\n",
    "                \n",
    "                if found_retro:\n",
    "                    # Continúa procesando 6 ul más después de encontrar \"Retro\"\n",
    "                    if ul_counter >= 6:\n",
    "                        print(\"Se procesaron 6 ul adicionales después de 'Retro'. Terminando la extracción.\")\n",
    "                        break\n",
    "                \n",
    "                else:\n",
    "                    # Verifica si hay un h3 con el texto 'Retro' después del current_element\n",
    "                    try:\n",
    "                        retro_h3 = driver.find_element(By.XPATH, \"//h3[contains(text(), 'Retro')]\")\n",
    "                        print(\"Encontrado h3 con texto 'Retro'. Continuando con la extracción de 6 ul más.\")\n",
    "                        found_retro = True\n",
    "                        ul_counter = 0  # Reiniciar el contador para procesar 6 ul más\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                # Mueve el foco al ul actual antes de hacer scroll\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView();\", ul_element)\n",
    "                print(f\"Foco en ul actual antes de AvPag.\")\n",
    "                \n",
    "                # Presiona AvPag para continuar cargando contenido\n",
    "                press_page_down(1)\n",
    "                scrolls_done += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"No se encontraron más ul después de 'Películas' o se alcanzó 'Retro'. Error: {e}\")\n",
    "                break\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al encontrar el h3 'Películas': {e}\")\n",
    "    \n",
    "    return hrefs\n",
    "\n",
    "# Función para presionar AvPag\n",
    "def press_page_down(times):\n",
    "    actions = ActionChains(driver)\n",
    "    for _ in range(times):\n",
    "        actions.send_keys(Keys.PAGE_DOWN).perform()\n",
    "        time.sleep(2)  # Pausa para permitir la carga del contenido\n",
    "\n",
    "# Función para extraer hrefs de un ul\n",
    "def extract_hrefs_from_ul(ul_element):\n",
    "    hrefs = []\n",
    "    li_elements = ul_element.find_elements(By.TAG_NAME, 'li')\n",
    "    for li in li_elements:\n",
    "        a_tag = li.find_element(By.TAG_NAME, 'a')\n",
    "        hrefs.append(a_tag.get_attribute('href'))\n",
    "    return hrefs\n",
    "\n",
    "# Ejecuta la función para extraer los hrefs\n",
    "peliculas_hrefs = process_ul_after_peliculas()\n",
    "\n",
    "# Imprime las URLs extraídas\n",
    "print(f\"Películas URLs: {peliculas_hrefs}\")\n",
    "\n",
    "# Cierra el navegador\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INGRESAR A CADA DETALLE y EXTRAER DATOS\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "def extract_info_from_li(info_inner_lis):\n",
    "    rating = \"\"\n",
    "    content_type = \"\"\n",
    "    seasons_or_duration = \"\"\n",
    "\n",
    "    for li in info_inner_lis:\n",
    "        try:\n",
    "            # Busca si hay un <span> con la clase 'rating' dentro del <li>\n",
    "            span = li.find_element(By.TAG_NAME, 'span')\n",
    "            if 'rating' in span.get_attribute('class'):\n",
    "                rating = li.text\n",
    "        except:\n",
    "            text = li.text.strip()\n",
    "            if text and 'separator' not in li.get_attribute('class'):\n",
    "                if 'min' in text or 'Season' in text or 'Available' in text:\n",
    "                    seasons_or_duration = text\n",
    "                elif not content_type:\n",
    "                    content_type = text\n",
    "                else:\n",
    "                    seasons_or_duration = text\n",
    "\n",
    "    return rating, content_type, seasons_or_duration\n",
    "\n",
    "def check_links_status_with_selenium(links):\n",
    "    status_results = []\n",
    "    \n",
    "    for index, link in enumerate(links):\n",
    "        try:\n",
    "            print(f\"Accediendo al link {index + 1}/{len(links)}: {link}\")\n",
    "            \n",
    "            # Navega a la URL\n",
    "            driver.get(link)\n",
    "            \n",
    "            # Espera a que aparezca el div con id 'overlay-container' o la clase 'overlayContainer-0-2-15'\n",
    "            try:\n",
    "                overlay_element = WebDriverWait(driver, 20).until(\n",
    "                    EC.presence_of_element_located(\n",
    "                        (By.ID, 'overlay-container')\n",
    "                    )\n",
    "                )\n",
    "            except:\n",
    "                try:\n",
    "                    overlay_element = WebDriverWait(driver, 20).until(\n",
    "                        EC.presence_of_element_located(\n",
    "                            (By.CLASS_NAME, 'overlayContainer-0-2-15')\n",
    "                        )\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"No se encontró el overlay. Saltando al siguiente link. Error: {e}\")\n",
    "                    continue\n",
    "                \n",
    "            time.sleep(8)\n",
    "            \n",
    "            # TITLE\n",
    "            try:\n",
    "                header_element = overlay_element.find_element(By.TAG_NAME, 'header')\n",
    "                h1_element = header_element.find_element(By.TAG_NAME, 'h1')\n",
    "                h1_text = h1_element.text\n",
    "                print(f\"Texto del h1: {h1_text}\")\n",
    "            except Exception as e:\n",
    "                h1_text = f\"No se pudo encontrar el h1: {e}\"\n",
    "           \n",
    "            # DESCRIPTION\n",
    "            try:\n",
    "                div_inner = driver.find_element(By.CSS_SELECTOR, 'div.inner')\n",
    "                p_element = div_inner.find_element(By.TAG_NAME, 'p')\n",
    "                description_p = p_element.text\n",
    "            except Exception as e:\n",
    "                description_p = f\"No se pudo encontrar la descripción: {e}\"\n",
    "            print(description_p)\n",
    "\n",
    "            # INFORMATION\n",
    "            try:\n",
    "                info_inner_lis = div_inner.find_elements(By.TAG_NAME, 'li')\n",
    "                rating, content_type, seasons_or_duration = extract_info_from_li(info_inner_lis)\n",
    "                \n",
    "                # RESULTADOS\n",
    "                print(f\"Rating: {rating}\")\n",
    "                print(f\"Tipo de Contenido: {content_type}\")\n",
    "                print(f\"Temporadas o Duración: {seasons_or_duration}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error al extraer la información: {e}\")\n",
    "                rating, content_type, seasons_or_duration = \"\", \"\", \"\"\n",
    "\n",
    "            # CHECK FOR SEASONS\n",
    "            try:\n",
    "                season_div = driver.find_element(By.CLASS_NAME, 'season-select')\n",
    "                select_element = season_div.find_element(By.TAG_NAME, 'select')\n",
    "                select = Select(select_element)\n",
    "                \n",
    "                seasons_info = []\n",
    "                for option in select.options:\n",
    "                    season = option.text.strip()\n",
    "                    print(f\"Temporada encontrada: {season}\")\n",
    "                    select.select_by_visible_text(season)\n",
    "                    time.sleep(3)  \n",
    "                    \n",
    "                    episode_elements = driver.find_elements(By.CSS_SELECTOR, 'li.episode-container-atc')\n",
    "                    for episode in episode_elements:\n",
    "                        section_detail = episode.find_element(By.CSS_SELECTOR, 'section.episode-details')\n",
    "                        h3_detail_episode = section_detail.find_element(By.CSS_SELECTOR, 'h3.episode-name-atc').text\n",
    "                        p_detail_episode = section_detail.find_element(By.CSS_SELECTOR, 'p.episode-description-atc').text\n",
    "                        \n",
    "                        try:\n",
    "                            episode_metadata = episode.find_element(By.CLASS_NAME, 'episode-metadata-atc')\n",
    "                            episode_numbers = episode_metadata.find_element(By.CLASS_NAME, 'numbers')\n",
    "                            episode_number = episode_numbers.find_elements(By.TAG_NAME, 'span')[0].text\n",
    "                            episode_duration = episode_numbers.find_elements(By.TAG_NAME, 'span')[1].text\n",
    "                        except Exception as e:\n",
    "                            episode_number = \"No disponible\"\n",
    "                            episode_duration = \"No disponible\"\n",
    "                            print(f\"No se pudieron extraer los datos del episodio: {e}\")\n",
    "\n",
    "                        seasons_info.append({\n",
    "                            'season': season,\n",
    "                            'Title episode': h3_detail_episode,\n",
    "                            'Description episode': p_detail_episode,\n",
    "                            'Episode number': episode_number,\n",
    "                            'Duration': episode_duration\n",
    "                        })\n",
    "                \n",
    "                content_type = \"Serie\"\n",
    "                print(f\"Información de temporadas y capítulos extraída.\")\n",
    "                print(seasons_info)\n",
    "            except Exception as e:\n",
    "                content_type = \"Película\"\n",
    "                print(f\"No se encontró la selección de temporadas. Es probable que sea una película. Error: {e}\")\n",
    "            \n",
    "            status_results.append({\n",
    "                'Url': link,\n",
    "                'Type': content_type,\n",
    "                'Title': h1_text,\n",
    "                'Resume': description_p,\n",
    "                'Rating': rating,\n",
    "                'Content Type': content_type,\n",
    "                'Duration': seasons_or_duration,\n",
    "                'Seasons': seasons_info if content_type == \"Serie\" else 'No aplica'\n",
    "            })\n",
    "            print(f\"Información extraída del link {index + 1}/{len(links)}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            status_results.append({\n",
    "                'url': link,\n",
    "                'type': 'Error',\n",
    "                'title': 'Error',\n",
    "                'description': str(e)\n",
    "            })\n",
    "            print(f\"Error al acceder al link {index + 1}/{len(links)}: {e}\")\n",
    "    \n",
    "    return status_results\n",
    "\n",
    "# Ejecuta la función con las URLs almacenadas en peliculas_hrefs\n",
    "status_results = check_links_status_with_selenium(peliculas_hrefs)\n",
    "\n",
    "# Convertir los resultados a un DataFrame de Pandas\n",
    "df = pd.DataFrame(status_results)\n",
    "\n",
    "# Exportar el DataFrame a un archivo Excel\n",
    "excel_path = 'On-Demand-PlutoTV.xlsx'\n",
    "df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "\n",
    "print(f\"Resultados exportados a {excel_path}\")\n",
    "\n",
    "# Cierra el navegador\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "end_time_ondemand = time.time()\n",
    "execution_time_ondemand = end_time_ondemand - start_time_ondemand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PAGE LIVE TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Comenzar a medir el tiempo de ejecución\n",
    "start_time_livetv = time.time()\n",
    "\n",
    "\n",
    "# Definir un User-Agent personalizado\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36\"\n",
    "\n",
    "# Configurar las opciones de Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(f'user-agent={user_agent}')\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--disable-images\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.headless = True\n",
    "\n",
    "# Iniciar el navegador con las opciones configuradas\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Navegar a la página de Pluto.tv\n",
    "driver.get('https://pluto.tv/latam/live-tv')\n",
    "\n",
    "# Espera que la página cargue completamente\n",
    "driver.implicitly_wait(15)\n",
    "time.sleep(5)\n",
    "\n",
    "# Lista para almacenar los datos\n",
    "data_list = []\n",
    "\n",
    "# Función para hacer scroll suave\n",
    "def scroll_smoothly():\n",
    "    driver.execute_script(\"window.scrollBy(0, window.innerHeight);\")  # Desplazarse hacia abajo en la ventana visible\n",
    "    time.sleep(2)  # Esperar para que se cargue el contenido adicional\n",
    "\n",
    "# Obtener los divs visibles\n",
    "def get_divs():\n",
    "    return driver.find_elements(By.CSS_SELECTOR, 'div[class^=\"channelListItem\"]')\n",
    "\n",
    "# Función para hacer clic en un `li` y mostrar su texto\n",
    "def click_and_show_text(li):\n",
    "    try:\n",
    "        # Imprimir el texto del `li`\n",
    "        li_text = li.text\n",
    "        print(f\"Haciendo clic en la categoría: {li_text}\")\n",
    "        \n",
    "        # Hacer clic en el `li`\n",
    "        li.click()\n",
    "        time.sleep(2)  # Esperar para que la página cargue la nueva sección\n",
    "        \n",
    "        # Asegurarse de que la página esté enfocada en los nuevos `divs`\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", li)\n",
    "        time.sleep(2)  # Esperar para asegurarse de que los `divs` estén visibles\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error al hacer clic en el `li`: {e}\")\n",
    "        return False\n",
    "\n",
    "# Obtener los elementos de la lista en el menú lateral\n",
    "category_items = driver.find_elements(By.CSS_SELECTOR, 'ul li')  # Asegúrate de que el selector coincide con los `li` en el menú lateral\n",
    "\n",
    "# Procesar los divs\n",
    "def process_divs(divs):\n",
    "    for index, div in enumerate(divs):\n",
    "        if index > 0:\n",
    "            print(f\"Haciendo clic en el primer gridcell del div #{index} para activar la data\")\n",
    "            try:\n",
    "                first_gridcell = div.find_element(By.CSS_SELECTOR, 'div[role=\"gridcell\"]')\n",
    "                first_gridcell.click()\n",
    "                time.sleep(2)  # Esperar a que se active el gridcell\n",
    "            except Exception as e:\n",
    "                print(f\"Error al hacer clic en el primer gridcell del div #{index}: {e}\")\n",
    "                continue  # Continuar con el siguiente div\n",
    "\n",
    "        print(f\"Procesando div #{index}\")\n",
    "\n",
    "        # Iterar sobre los gridcells dentro del div actual\n",
    "        gridcells = div.find_elements(By.CSS_SELECTOR, 'div[role=\"gridcell\"]')\n",
    "\n",
    "        for grid_index, gridcell in enumerate(gridcells):\n",
    "            print(f\"Procesando gridcell #{grid_index} dentro del div #{index}\")\n",
    "\n",
    "            # Forzar visibilidad de los elementos con opacidad 0\n",
    "            driver.execute_script(\"arguments[0].style.opacity = 1;\", gridcell)\n",
    "            \n",
    "            time.sleep(0.5)\n",
    "\n",
    "            try:\n",
    "                container_data = gridcell.find_element(By.CSS_SELECTOR, 'div.timelineSkeletonContainer')\n",
    "                \n",
    "                # Forzar visibilidad de elementos .description y todos los spans dentro de .metadata-0-2-281\n",
    "                description_element = container_data.find_element(By.CSS_SELECTOR, 'div.description')\n",
    "                driver.execute_script(\"arguments[0].style.opacity = 1;\", description_element)\n",
    "                \n",
    "                time.sleep(1)\n",
    "\n",
    "                div_metadata = container_data.find_element(By.CSS_SELECTOR, 'div[class^=\"metadata\"]')\n",
    "                spans = div_metadata.find_elements(By.TAG_NAME, 'span')\n",
    "                for span in spans:\n",
    "                    driver.execute_script(\"arguments[0].style.opacity = 1;\", span)\n",
    "                    time.sleep(0.1)\n",
    "\n",
    "                # Extraer la descripción\n",
    "                span_description = description_element.find_element(By.TAG_NAME, 'span').text if description_element.find_elements(By.TAG_NAME, 'span') else 'N/A'\n",
    "\n",
    "                # Extraer el título del programa\n",
    "                title_tv = container_data.find_element(By.CSS_SELECTOR, 'span.name-item').text if container_data.find_elements(By.CSS_SELECTOR, 'span.name-item') else 'N/A'\n",
    "\n",
    "                # Extraer rating\n",
    "                span_rating = div_metadata.find_element(By.CSS_SELECTOR, 'span.rating').text if div_metadata.find_elements(By.CSS_SELECTOR, 'span.rating') else 'N/A'\n",
    "                \n",
    "                # Extraer temporada y episodio, verificando la cantidad de spans y su contenido\n",
    "                season_number = 'N/A'\n",
    "                episode_number = 'N/A'\n",
    "                episode_name = 'N/A'\n",
    "                \n",
    "                if len(spans) > 0:\n",
    "                    for span in spans:\n",
    "                        text = span.text.strip()\n",
    "                        if text.startswith('T') or text.startswith('S'):\n",
    "                            season_number = text\n",
    "                        elif text.startswith('E') or text.startswith('Episode'):\n",
    "                            episode_number = text\n",
    "                \n",
    "                if len(spans) > 4:\n",
    "                    episode_name = spans[4].text.strip()\n",
    "                \n",
    "                # Agregar los datos a la lista\n",
    "                data_list.append({\n",
    "                    'Title': title_tv,\n",
    "                    'Rating': span_rating,\n",
    "                    'Season': season_number,\n",
    "                    'Episode': episode_number,\n",
    "                    'Episode Name': episode_name,\n",
    "                    'Description': span_description\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error al procesar gridcell #{grid_index} dentro del div #{index}: {e}\")\n",
    "                continue  # Continuar con el siguiente gridcell\n",
    "\n",
    "# Procesar cada categoría\n",
    "for index, category in enumerate(category_items):\n",
    "    if click_and_show_text(category):\n",
    "        # Obtener los divs iniciales\n",
    "        previous_divs = get_divs()\n",
    "        \n",
    "        # Bucle para hacer scroll y procesar los divs\n",
    "        while True:\n",
    "            scroll_smoothly()\n",
    "            time.sleep(2)  # Esperar para que se cargue el contenido adicional\n",
    "\n",
    "            # Obtener los nuevos divs visibles\n",
    "            current_divs = get_divs()\n",
    "            \n",
    "            # Procesar los divs visibles actuales\n",
    "            process_divs(current_divs)\n",
    "            \n",
    "            # Verificar si hay nuevos divs para procesar\n",
    "            if len(current_divs) == len(previous_divs):\n",
    "                print(\"No hay más divs nuevos.\")\n",
    "                break\n",
    "            \n",
    "            # Actualizar la lista de divs anteriores\n",
    "            previous_divs = current_divs\n",
    "\n",
    "# Convertir la lista de datos a un DataFrame\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Guardar el DataFrame en un archivo Excel\n",
    "df.to_excel('Live-TV-PlutoTV.xlsx', index=False)\n",
    "\n",
    "# Cerrar el navegador\n",
    "driver.quit()\n",
    "\n",
    "\n",
    "# Medir el tiempo de ejecución\n",
    "end_time_livetv = time.time()\n",
    "execution_time_livetv = end_time_livetv - start_time_livetv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_time_total = execution_time_ondemand + execution_time_livetv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
